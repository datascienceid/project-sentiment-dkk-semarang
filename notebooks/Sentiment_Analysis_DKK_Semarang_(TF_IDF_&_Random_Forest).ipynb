{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of Sentiment Analysis DKK Semarang (TF-IDF & Random Forest)",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03gRp0MJmqZI",
        "outputId": "6081bef1-d479-4fb0-ff7e-2cd5161afd10"
      },
      "source": [
        "!pip install emoji\n",
        "!pip install scikit-learn==1.0.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji\n",
            "  Downloading emoji-1.6.1.tar.gz (170 kB)\n",
            "\u001b[?25l\r\u001b[K     |██                              | 10 kB 20.5 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 20 kB 23.7 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 30 kB 26.0 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 40 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 51 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 61 kB 30.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 71 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 81 kB 30.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 92 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 102 kB 29.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 112 kB 29.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 122 kB 29.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 133 kB 29.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 143 kB 29.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 153 kB 29.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 163 kB 29.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 170 kB 29.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.6.1-py3-none-any.whl size=169314 sha256=2d352e3344227939d7d7216fd2db38efb14731320f023806827b54d0c2f379c7\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/5f/d3/03d313ddb3c2a1a427bb4690f1621eea60fe6f2a30cc95940f\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-1.6.1\n",
            "Requirement already satisfied: scikit-learn==1.0.1 in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==1.0.1) (3.0.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==1.0.1) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==1.0.1) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==1.0.1) (1.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O73_3IGSiStg"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XM2i-RdoiTy7"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import string, re, requests, csv\n",
        "from google.colab import drive\n",
        "from wordcloud import WordCloud\n",
        "from gensim.corpora import WikiCorpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TUbZKrJiVOU",
        "outputId": "63cb0cbf-8bca-495b-e0ba-07b29c0513d9"
      },
      "source": [
        "from nltk import word_tokenize, sent_tokenize\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_ovLo6EiX2_"
      },
      "source": [
        "# Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "8qMho9XsiWdX",
        "outputId": "08ba53a4-01f6-4100-bd6b-63acda865029"
      },
      "source": [
        "train = pd.read_csv('/content/train.csv')\n",
        "test = pd.read_csv('/content/test.csv')\n",
        "\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>username</th>\n",
              "      <th>likes</th>\n",
              "      <th>datetime</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>🔥</td>\n",
              "      <td>negative</td>\n",
              "      <td>lanyardsemarang</td>\n",
              "      <td>0</td>\n",
              "      <td>2020-11-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Naik Turun maju can5ik 😂😂😂😂</td>\n",
              "      <td>neutral</td>\n",
              "      <td>hadi_soeparno</td>\n",
              "      <td>1</td>\n",
              "      <td>2021-03-29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Prosentase tingkat kematian karena covid 19 ut...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>heryadisaputro</td>\n",
              "      <td>0</td>\n",
              "      <td>2020-09-22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Rapid test/ test swab PCR Di DKK/dinkes Semara...</td>\n",
              "      <td>negative</td>\n",
              "      <td>airlangga15</td>\n",
              "      <td>0</td>\n",
              "      <td>2020-05-29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Min, area pedurungan bs dilakukan dmn,</td>\n",
              "      <td>neutral</td>\n",
              "      <td>fauzanabell</td>\n",
              "      <td>0</td>\n",
              "      <td>2021-06-22</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ...    datetime\n",
              "0                                                  🔥  ...  2020-11-02\n",
              "1                        Naik Turun maju can5ik 😂😂😂😂  ...  2021-03-29\n",
              "2  Prosentase tingkat kematian karena covid 19 ut...  ...  2020-09-22\n",
              "3  Rapid test/ test swab PCR Di DKK/dinkes Semara...  ...  2020-05-29\n",
              "4             Min, area pedurungan bs dilakukan dmn,  ...  2021-06-22\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSpz3SrTigew"
      },
      "source": [
        "# EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrLHGvjxjNP_"
      },
      "source": [
        "## Wordcloud"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbVXS7syidAd"
      },
      "source": [
        "# positive comments before preprocessing\n",
        "# data_pos = train[train['label'] == 'positive']\n",
        "\n",
        "# all_text = ' '.join(word for word in data_pos['text'])\n",
        "# wordcloud = WordCloud(colormap='Greens', width=1000, height=1000, mode='RGBA', background_color='white').generate(all_text)\n",
        "# plt.figure(figsize=(20,10))\n",
        "# plt.imshow(wordcloud, interpolation='bilinear')\n",
        "# plt.axis(\"off\")\n",
        "# plt.margins(x=0, y=0)\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9yRzPoYimIE"
      },
      "source": [
        "# negative comments before preprocessing\n",
        "# data_neg = train[train['label'] == 'negative']\n",
        "\n",
        "# all_text = ' '.join(word for word in data_neg['text'])\n",
        "# wordcloud = WordCloud(colormap='Reds', width=1000, height=1000, mode='RGBA', background_color='white').generate(all_text)\n",
        "# plt.figure(figsize=(20,10))\n",
        "# plt.imshow(wordcloud, interpolation='bilinear')\n",
        "# plt.axis(\"off\")\n",
        "# plt.margins(x=0, y=0)\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Olxg2IjAjByz"
      },
      "source": [
        "# neutral comments before preprocessing\n",
        "# data_neut = train[train['label'] == 'neutral']\n",
        "\n",
        "# all_text = ' '.join(word for word in data_neut['text'])\n",
        "# wordcloud = WordCloud(colormap='Blues', width=1000, height=1000, mode='RGBA', background_color='white').generate(all_text)\n",
        "# plt.figure(figsize=(20,10))\n",
        "# plt.imshow(wordcloud, interpolation='bilinear')\n",
        "# plt.axis(\"off\")\n",
        "# plt.margins(x=0, y=0)\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBmjPgdt_Obw",
        "outputId": "1e980355-a03f-42c9-ceb0-3f2726c9be14"
      },
      "source": [
        "# value counts\n",
        "train['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "neutral     2926\n",
              "negative    2775\n",
              "positive    2266\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vygorxeojRKo"
      },
      "source": [
        "# Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-RvDQEljeEV"
      },
      "source": [
        "train_text = train['text']\n",
        "test_text = test['text']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrdujBtLkUoW"
      },
      "source": [
        "## Rename username"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RakrbjBhjG_n"
      },
      "source": [
        "pattern = \"(?:@)([A-Za-z0-9_](?:(?:[A-Za-z0-9_]|(?:\\.(?!\\.))){0,28}(?:[A-Za-z0-9_]))?)\"\n",
        "\n",
        "train_text = train_text.apply(lambda x: re.sub(pattern, \"@username\", x))\n",
        "test_text = test_text.apply(lambda x: re.sub(pattern, \"@username\", x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvUa_fVgkXVB"
      },
      "source": [
        "## Cleansing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVRdg8Dnj3lX"
      },
      "source": [
        "def cleansing(data):\n",
        "\n",
        "    # lowercasing\n",
        "    data = data.lower()\n",
        "\n",
        "    # remove punctuation\n",
        "    punct = string.punctuation\n",
        "    translator = str.maketrans(punct, ' '*len(punct))\n",
        "    data = data.translate(translator)\n",
        "\n",
        "    # remove ASCII dan unicode\n",
        "    # data = data.encode('ascii', 'ignore').decode('utf-8')\n",
        "    # data = re.sub(r'[^\\x00-\\x7f]',r'', data)\n",
        "    \n",
        "    # remove newline\n",
        "    data = data.replace('\\n', ' ')\n",
        "\n",
        "    # remove digit\n",
        "    pattern = r'[0-9]'\n",
        "    data = re.sub(pattern, '', data)\n",
        "\n",
        "    # remove extra space\n",
        "    data = ' '.join(data.split())\n",
        "    \n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9yLdhQpj7jk"
      },
      "source": [
        "train_text = train_text.apply(lambda x: cleansing(x))\n",
        "test_text = test_text.apply(lambda x: cleansing(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pybHzwOnj-am",
        "outputId": "792cd970-eefc-455a-aa1b-c8ea1a5e60e1"
      },
      "source": [
        "train_text.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                                    🔥\n",
              "1                           naik turun maju canik 😂😂😂😂\n",
              "2    prosentase tingkat kematian karena covid utk w...\n",
              "3    rapid test test swab pcr di dkk dinkes semaran...\n",
              "4                 min area pedurungan bs dilakukan dmn\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAHeivs2kZkq"
      },
      "source": [
        "## Remove emojis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "os8qJbMKkHrX"
      },
      "source": [
        "# import sys\n",
        "\n",
        "# def remove_emoji(data):\n",
        "#     emoji_pattern = re.compile(\"[\"\n",
        "#                            u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "#                            u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "#                            u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "#                            u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "#                            u\"\\U00002702-\\U000027B0\"\n",
        "#                            u\"\\U000024C2-\\U0001F251\"\n",
        "#                            \"]+\", flags=re.UNICODE)\n",
        "#     return emoji_pattern.sub(r' ', data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzBowd03kN2Q"
      },
      "source": [
        "# train_text = train_text.apply(lambda x: remove_emoji(x))\n",
        "# test_text = test_text.apply(lambda x: remove_emoji(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5iXH9Q_kQgC"
      },
      "source": [
        "# train_text.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bz9oPaSCLfzy"
      },
      "source": [
        "# Replace emoji with text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "iEd7ztF5LqXS",
        "outputId": "22878637-1cf5-47e9-d70e-99346d3c78e6"
      },
      "source": [
        "df_emoji = pd.read_csv('emoji_to_text.csv')\n",
        "df_emoji.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emoji</th>\n",
              "      <th>makna</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>😴</td>\n",
              "      <td>Wajah Tertidur</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>🤤</td>\n",
              "      <td>Meneteskan Air Liur</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>😷</td>\n",
              "      <td>Wajah Ditutupi Masker</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>🤒</td>\n",
              "      <td>Wajah dengan Termometer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>🤕</td>\n",
              "      <td>Wajah Diperban</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  emoji                    makna\n",
              "0     😴           Wajah Tertidur\n",
              "1     🤤      Meneteskan Air Liur\n",
              "2     😷    Wajah Ditutupi Masker\n",
              "3     🤒  Wajah dengan Termometer\n",
              "4     🤕           Wajah Diperban"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrv8RKPWLxxB"
      },
      "source": [
        "UNICODE_EMO = {row['emoji']:row['makna'] for idx,row in df_emoji.iterrows()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S94rDfJqLiTo"
      },
      "source": [
        "import emoji\n",
        "import functools\n",
        "import operator\n",
        "import re\n",
        "\n",
        "def convert_emojis(text):\n",
        "    # split emojis\n",
        "    em_split_emoji = emoji.get_emoji_regexp().split(text)\n",
        "    em_split_whitespace = [substr.split() for substr in em_split_emoji]\n",
        "    em_split = functools.reduce(operator.concat, em_split_whitespace)\n",
        "    text = ' '.join(em_split)\n",
        "\n",
        "    # convert emojis\n",
        "    for emot in UNICODE_EMO:\n",
        "        text = re.sub(r'('+emot+')', \"_\".join(UNICODE_EMO[emot].replace(\",\",\"\").replace(\":\",\"\").split()), text)\n",
        "    return text.lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hp2NjvgjMWw_"
      },
      "source": [
        "train_text = train_text.apply(lambda x: convert_emojis(x))\n",
        "test_text = test_text.apply(lambda x: convert_emojis(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "js9okD9BMaVL",
        "outputId": "7083b66e-eb7d-4fb8-bee0-2e6bda3d4d95"
      },
      "source": [
        "train.iloc[1], train_text.iloc[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(text        Naik Turun maju can5ik 😂😂😂😂\n",
              " label                           neutral\n",
              " username                  hadi_soeparno\n",
              " likes                                 1\n",
              " datetime                     2021-03-29\n",
              " Name: 1, dtype: object,\n",
              " 'naik turun maju canik wajah_tertawa_sampai_menangis wajah_tertawa_sampai_menangis wajah_tertawa_sampai_menangis wajah_tertawa_sampai_menangis')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlCcXGlrkb5V"
      },
      "source": [
        "## Normalize kata alay/colloquial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLJrHUvAkRNO"
      },
      "source": [
        "# CONSTRUCT KAMUS ALAY\n",
        "text_path1 = 'https://raw.githubusercontent.com/ramaprakoso/analisis-sentimen/master/kamus/kbba.txt'\n",
        "text_path2 = 'https://raw.githubusercontent.com/nasalsabila/kamus-alay/master/colloquial-indonesian-lexicon.csv'\n",
        "kamus_alay1 = pd.read_csv(text_path1, delimiter=\"\\t\", header=None, names=['slang', 'formal'])\n",
        "kamus_alay2 = pd.read_csv(text_path2)\n",
        "kamus_alay = pd.concat([kamus_alay1, kamus_alay2[['slang', 'formal']]]).reset_index(drop=True)\n",
        "\n",
        "dict_alay = dict()\n",
        "for index, row in kamus_alay.iterrows():\n",
        "    dict_alay[row['slang']] = row['formal']\n",
        "\n",
        "def normalize_text(data):\n",
        "  word_tokens = word_tokenize(data)\n",
        "  result = [dict_alay.get(w,w) for w in word_tokens]\n",
        "  return ' '.join(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoZlaVb-kj08"
      },
      "source": [
        "train_text = train_text.apply(lambda x: normalize_text(x))\n",
        "test_text = test_text.apply(lambda x: normalize_text(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3M8uZvjkn1S",
        "outputId": "a6affcf7-8575-4525-d4a4-2e11d763a3ab"
      },
      "source": [
        "train_text.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                                  api\n",
              "1    naik turun maju canik wajah_tertawa_sampai_men...\n",
              "2    prosentase tingkat kematian karena covid untuk...\n",
              "3    rapid test test swab pcr di dan kawan-kawan di...\n",
              "4            min area pedurungan bisa dilakukan dimana\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzlZad8Cktsv"
      },
      "source": [
        "## Spelling correction (not implemented yet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpS77077kxts"
      },
      "source": [
        "## Remove stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6_40yfskoqx"
      },
      "source": [
        "# CONSTRUCT STOPWORDS\n",
        "rama_stopword = \"https://raw.githubusercontent.com/ramaprakoso/analisis-sentimen/master/kamus/stopword.txt\"\n",
        "yutomo_stopword = \"https://raw.githubusercontent.com/yasirutomo/python-sentianalysis-id/master/data/feature_list/stopwordsID.txt\"\n",
        "fpmipa_stopword = \"https://raw.githubusercontent.com/onlyphantom/elangdev/master/elang/word2vec/utils/stopwords-list/fpmipa-stopwords.txt\"\n",
        "sastrawi_stopword = \"https://raw.githubusercontent.com/onlyphantom/elangdev/master/elang/word2vec/utils/stopwords-list/sastrawi-stopwords.txt\"\n",
        "aliakbar_stopword = \"https://raw.githubusercontent.com/onlyphantom/elangdev/master/elang/word2vec/utils/stopwords-list/aliakbars-bilp.txt\"\n",
        "pebahasa_stopword = \"https://raw.githubusercontent.com/onlyphantom/elangdev/master/elang/word2vec/utils/stopwords-list/pebbie-pebahasa.txt\"\n",
        "elang_stopword = \"https://raw.githubusercontent.com/onlyphantom/elangdev/master/elang/word2vec/utils/stopwords-id.txt\"\n",
        "nltk_stopword = stopwords.words('indonesian')\n",
        "\n",
        "path_stopwords = [rama_stopword, yutomo_stopword, fpmipa_stopword, sastrawi_stopword, \n",
        "                  aliakbar_stopword, pebahasa_stopword, elang_stopword]\n",
        "\n",
        "# CUSTOM STOPWORDS\n",
        "other = '''\n",
        "admin mimin min minkes kalo nya username\n",
        "'''\n",
        "\n",
        "# gabungkan stopwords\n",
        "stopwords_l = nltk_stopword\n",
        "for path in path_stopwords:\n",
        "    response = requests.get(path)\n",
        "    stopwords_l += response.text.split('\\n')\n",
        "\n",
        "st_words = set(stopwords_l)\n",
        "other_stopword = set(other.split())\n",
        "\n",
        "stop_words = st_words | other_stopword\n",
        "\n",
        "\n",
        "def remove_stopword(text, stop_words=stop_words):\n",
        "    word_tokens = word_tokenize(text)\n",
        "    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
        "    return ' '.join(filtered_sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZT0xjKaOk3jr"
      },
      "source": [
        "train_text = train_text.apply(lambda x: remove_stopword(x))\n",
        "test_text = test_text.apply(lambda x: remove_stopword(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovtkXuMrk8qt",
        "outputId": "3f0db8fe-6c3f-4c4a-e4c8-01efbd9cbb9a"
      },
      "source": [
        "train_text.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                                  api\n",
              "1    turun maju canik wajah_tertawa_sampai_menangis...\n",
              "2        prosentase kematian covid warga kota semarang\n",
              "3    rapid test test swab pcr kawan-kawan dinkes se...\n",
              "4                                      area pedurungan\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxpRrMG7lBWN"
      },
      "source": [
        "# Feature extraction (TF-IDF)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imyHnMmdk9zJ"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(min_df=2, max_df=0.95, max_features = 5000, ngram_range = (1, 3),\n",
        "                             sublinear_tf = True )\n",
        "\n",
        "train_features = vectorizer.fit_transform(train_text)\n",
        "test_features = vectorizer.transform(test_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VNZWddslhUC",
        "outputId": "11f9e1fa-e313-40d7-9a8d-17b67d74052a"
      },
      "source": [
        "train_features.toarray().shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7967, 5000)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17TUJSAfldS-"
      },
      "source": [
        "# export tf-idf vectorizer\n",
        "# from joblib import dump, load\n",
        "\n",
        "# dump(vectorizer, 'tfidf-vectorizer.joblib')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeLU0u8gmASE"
      },
      "source": [
        "# vct = load('tfidf-vectorizer.joblib')\n",
        "# vct.transform(test_text).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B008EKh1lmpc"
      },
      "source": [
        "# Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N73a0FT2mPJ7"
      },
      "source": [
        "# mapping label\n",
        "mapper = {'neutral':0, 'positive':1, 'negative':2}\n",
        "train_y = train['label'].map(mapper)\n",
        "test_y = test['label'].map(mapper)\n",
        "\n",
        "# train_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xF5fY4xylkNK",
        "outputId": "f8f73540-95cf-4a8a-e3a8-62fbae8b4027"
      },
      "source": [
        "%%time\n",
        "# from sklearn.svm import SVC\n",
        "\n",
        "# clf = SVC()\n",
        "# clf.fit(train_features, train_y)\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "clf = RandomForestClassifier()\n",
        "clf.fit(train_features, train_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 8.7 s, sys: 32 ms, total: 8.74 s\n",
            "Wall time: 8.7 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5oUDrQ5sV0s",
        "outputId": "c92060dc-f537-4038-a374-4ace97459bf6"
      },
      "source": [
        "clf.get_params()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bootstrap': True,\n",
              " 'ccp_alpha': 0.0,\n",
              " 'class_weight': None,\n",
              " 'criterion': 'gini',\n",
              " 'max_depth': None,\n",
              " 'max_features': 'auto',\n",
              " 'max_leaf_nodes': None,\n",
              " 'max_samples': None,\n",
              " 'min_impurity_decrease': 0.0,\n",
              " 'min_samples_leaf': 1,\n",
              " 'min_samples_split': 2,\n",
              " 'min_weight_fraction_leaf': 0.0,\n",
              " 'n_estimators': 100,\n",
              " 'n_jobs': None,\n",
              " 'oob_score': False,\n",
              " 'random_state': None,\n",
              " 'verbose': 0,\n",
              " 'warm_start': False}"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjfTei6gnLhr",
        "outputId": "a29b6d6c-940d-4a40-ba80-51c9ad5d054b"
      },
      "source": [
        "%%time\n",
        "# cross-val score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(clf, train_features, train_y, cv=5)\n",
        "print(scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.71894605 0.72710163 0.72881356 0.73195229 0.7131199 ]\n",
            "CPU times: user 36.2 s, sys: 78.9 ms, total: 36.3 s\n",
            "Wall time: 36.1 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from joblib import dump, load\n",
        "\n",
        "dump(clf, 'tfidf_rf.joblib') "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FO_FDVFMqqoT",
        "outputId": "8320fd0a-f6ee-4d76-de27-99b6df3af015"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tfidf_rf.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HBxvT4ql8P_"
      },
      "source": [
        "# predict\n",
        "y_pred = clf.predict(test_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ymq98Z6TmAGF",
        "outputId": "c02e6d88-ed05-4c39-e7d9-85b8a538d0aa"
      },
      "source": [
        "%%time\n",
        "# accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy = accuracy_score(test_y, y_pred)\n",
        "print(accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7228915662650602\n",
            "CPU times: user 920 µs, sys: 0 ns, total: 920 µs\n",
            "Wall time: 931 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf.get_params()"
      ],
      "metadata": {
        "id": "Rt42Dgn4sF6p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ff78d7c-0854-4267-8df0-c666c3367499"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bootstrap': True,\n",
              " 'ccp_alpha': 0.0,\n",
              " 'class_weight': None,\n",
              " 'criterion': 'gini',\n",
              " 'max_depth': None,\n",
              " 'max_features': 'auto',\n",
              " 'max_leaf_nodes': None,\n",
              " 'max_samples': None,\n",
              " 'min_impurity_decrease': 0.0,\n",
              " 'min_samples_leaf': 1,\n",
              " 'min_samples_split': 2,\n",
              " 'min_weight_fraction_leaf': 0.0,\n",
              " 'n_estimators': 100,\n",
              " 'n_jobs': None,\n",
              " 'oob_score': False,\n",
              " 'random_state': None,\n",
              " 'verbose': 0,\n",
              " 'warm_start': False}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nimZ4MiS9_GB"
      },
      "source": [
        "# from joblib import dump, load\n",
        "\n",
        "# dump(clf, 'tfidf_svc.joblib') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpXygsmd4OwE"
      },
      "source": [
        "GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWajvd5Y8Cjj"
      },
      "source": [
        "# train 1\n",
        "## kernel = linear\n",
        "## C = 1\n",
        "## gamma = scale\n",
        "## dfs = ovo\n",
        "\n",
        "# train 2\n",
        "## kernel = rbf\n",
        "## C = 1\n",
        "## gamma = scale\n",
        "## dfs = ovo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ymTv9t90MPh",
        "outputId": "526a0277-255f-4993-eaf9-fa74739ac854"
      },
      "source": [
        "%%time\n",
        "# Randomized Search\n",
        "# references: \n",
        "# https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import numpy as np\n",
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n",
        "\n",
        "clf = RandomForestClassifier()\n",
        "clf_random = RandomizedSearchCV(estimator=clf, \n",
        "                                param_distributions=random_grid, \n",
        "                                n_iter=100, \n",
        "                                cv=5, \n",
        "                                verbose=2, random_state=42, n_jobs=-1)\n",
        "# Fit the random search model\n",
        "clf_random.fit(train_features, train_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:705: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1min 36s, sys: 4.44 s, total: 1min 41s\n",
            "Wall time: 1h 46min 32s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXNhra140uIl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2de7e731-eea5-4ec3-e94f-d833a80a1e57"
      },
      "source": [
        "clf_random.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bootstrap': True,\n",
              " 'max_depth': None,\n",
              " 'max_features': 'sqrt',\n",
              " 'min_samples_leaf': 1,\n",
              " 'min_samples_split': 10,\n",
              " 'n_estimators': 1600}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fItVeHdEQmH",
        "outputId": "5c1a81e1-4096-4aca-c0ad-3d61a70e2ab8"
      },
      "source": [
        "y_pred = clf_random.predict(test_features)\n",
        "\n",
        "accuracy = accuracy_score(test_y, y_pred)\n",
        "print(accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7274096385542169\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9gi3aiFEilJ",
        "outputId": "fb007a81-7d33-44af-af36-136da50230d7"
      },
      "source": [
        "clf_random.get_params()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cv': 5,\n",
              " 'error_score': nan,\n",
              " 'estimator': RandomForestClassifier(),\n",
              " 'estimator__bootstrap': True,\n",
              " 'estimator__ccp_alpha': 0.0,\n",
              " 'estimator__class_weight': None,\n",
              " 'estimator__criterion': 'gini',\n",
              " 'estimator__max_depth': None,\n",
              " 'estimator__max_features': 'auto',\n",
              " 'estimator__max_leaf_nodes': None,\n",
              " 'estimator__max_samples': None,\n",
              " 'estimator__min_impurity_decrease': 0.0,\n",
              " 'estimator__min_samples_leaf': 1,\n",
              " 'estimator__min_samples_split': 2,\n",
              " 'estimator__min_weight_fraction_leaf': 0.0,\n",
              " 'estimator__n_estimators': 100,\n",
              " 'estimator__n_jobs': None,\n",
              " 'estimator__oob_score': False,\n",
              " 'estimator__random_state': None,\n",
              " 'estimator__verbose': 0,\n",
              " 'estimator__warm_start': False,\n",
              " 'n_iter': 100,\n",
              " 'n_jobs': -1,\n",
              " 'param_distributions': {'bootstrap': [True, False],\n",
              "  'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
              "  'max_features': ['auto', 'sqrt'],\n",
              "  'min_samples_leaf': [1, 2, 4],\n",
              "  'min_samples_split': [2, 5, 10],\n",
              "  'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]},\n",
              " 'pre_dispatch': '2*n_jobs',\n",
              " 'random_state': 42,\n",
              " 'refit': True,\n",
              " 'return_train_score': False,\n",
              " 'scoring': None,\n",
              " 'verbose': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWFoXR4iGai-",
        "outputId": "e21cb447-3d5f-4838-a25a-e58fbce51d2c"
      },
      "source": [
        "clf_random.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bootstrap': True,\n",
              " 'max_depth': None,\n",
              " 'max_features': 'sqrt',\n",
              " 'min_samples_leaf': 1,\n",
              " 'min_samples_split': 10,\n",
              " 'n_estimators': 1600}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d23OKBtXnhWf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "347ff17b-05bd-4cd4-e22d-7444d58f1fc8"
      },
      "source": [
        "%%time\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# params = {'kernel': ['linear', 'rbf', 'poly'],  # 3\n",
        "#           'C': [1, 0.25, 0.5, 0.75],            # 4\n",
        "#           'gamma': ['scale', 'auto', 1, 2, 3],  # 5\n",
        "#           'decision_function_shape': ['ovo','ovr'] # 2\n",
        "#           # 3 * 4 * 5 *2 * 5cv = 120 * 5 = 600 kombinasi\n",
        "# }\n",
        "\n",
        "# param_grid = { \n",
        "#     'n_estimators': [100, 200, 500],\n",
        "#     'max_features': ['auto', 'sqrt', 'log2'],\n",
        "#     'max_depth' : [2,3,4,5,6],\n",
        "#     'min_samples_leaf': [1,2,3],\n",
        "#     'criterion' :['gini', 'entropy']\n",
        "# }\n",
        "\n",
        "param_grid = {\n",
        "    'bootstrap': [True],\n",
        "    # 'max_depth': [100, 110, None],\n",
        "    # 'max_features': ['auto', 'sqrt'],\n",
        "    'min_samples_leaf': [1, 2, 3],\n",
        "    'min_samples_split': [8, 10, 12],\n",
        "    # 'criterion' :['gini'],\n",
        "    'n_estimators': [800, 1200, 1500, 1800]\n",
        "}\n",
        "\n",
        "clf = RandomForestClassifier()\n",
        "# cv_test = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "clf_grid = GridSearchCV(clf, param_grid, cv=5)\n",
        "clf_grid.fit(train_features, train_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1h 37min 31s, sys: 12.9 s, total: 1h 37min 44s\n",
            "Wall time: 1h 37min 27s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vd3OVGhyHmyt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "985b472a-0f72-4a9b-ccaa-11400493bd7d"
      },
      "source": [
        "# accuracy test\n",
        "y_pred = clf_grid.predict(test_features)\n",
        "\n",
        "accuracy = accuracy_score(test_y, y_pred)\n",
        "print(accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7289156626506024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9bxxzeh_yUl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a89d239a-a2bd-405e-c8a3-14f3658abee6"
      },
      "source": [
        "clf_grid.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bootstrap': True,\n",
              " 'min_samples_leaf': 1,\n",
              " 'min_samples_split': 12,\n",
              " 'n_estimators': 1800}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yG3k8a02_-4X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b89c32f-1b17-4827-d696-14272f1fecd5"
      },
      "source": [
        "%%time\n",
        "# cross-val score\n",
        "scores = cross_val_score(clf_grid, train_features, train_y, cv=5)\n",
        "print(scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.71706399 0.73525721 0.73320778 0.73822976 0.72441933]\n",
            "CPU times: user 9h 31min 4s, sys: 1min 8s, total: 9h 32min 12s\n",
            "Wall time: 9h 30min 14s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6M8Mjbn7yxzp"
      },
      "source": [
        "# param_grid = { \n",
        "#     'n_estimators': [100, 200, 500],\n",
        "#     'max_features': ['auto', 'sqrt', 'log2'],\n",
        "#     'max_depth' : [2,3,4,5,6],\n",
        "#     'min_samples_leaf': [1,2,3],\n",
        "#     'criterion' :['gini', 'entropy']\n",
        "# }\n",
        "\n",
        "# param_grid = {\n",
        "#     'bootstrap': [True],\n",
        "#     'max_depth': [80, 90, 100, 110],\n",
        "#     'max_features': [2, 3],\n",
        "#     'min_samples_leaf': [3, 4, 5],\n",
        "#     'min_samples_split': [8, 10, 12],\n",
        "#     'n_estimators': [100, 200, 300, 1000]\n",
        "# }\n",
        "\n",
        "# clf = RandomForestClassifier()\n",
        "# clf_grid = GridSearchCV(clf, param_grid)\n",
        "# clf_grid.fit(train_features, train_y)\n",
        "\n",
        "# print(clf.best_params_)\n",
        "\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# X_train,X_test,y_train,y_test = train_test_split(train_features, train_y, \n",
        "#                                                  test_size=0.33, \n",
        "#                                                  random_state=2021)\n",
        "# clf_grid = GridSearchCV(clf, param_grid)\n",
        "# clf_grid.fit(X_train, y_train)\n",
        "\n",
        "# print(clf.best_params_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCBVWzO7BIX8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f63d2dc-1eb1-485a-c1c2-292cddd9b80d"
      },
      "source": [
        "# accuracy test\n",
        "y_pred = clf_grid.predict(test_features)\n",
        "\n",
        "accuracy = accuracy_score(test_y, y_pred)\n",
        "print(accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7289156626506024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlHzUm0iBRN7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff727700-f281-409b-acff-2a6a1e24ea28"
      },
      "source": [
        "from joblib import dump, load\n",
        "\n",
        "dump(clf_grid, 'tfidf_rf_tuned.joblib') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tfidf_rf_tuned.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JPkSG5Ngtt9"
      },
      "source": [
        "# a = load(\"svc_tuned.joblib\")\n",
        "# b = a.predict(test_features)\n",
        "# accuracy_score(test_y, b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6INY5CNzhLJA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}